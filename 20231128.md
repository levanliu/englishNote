### What is "Information"?

Information, n. Knowledge communicated or received 
concerning a particular fact or circumstance.

### Quantifying Information (Claude Shannon,1948)

Suppose you're faced with N equally probable choices, and I give you
a fact that narrows it down to M choices. Then I've given you $log_2(N/M)$ bits of information.

Examples:
- information in one coin flip: $log_2(2/1)$ = 1 bit
- roll of 2 dice: $log_2(36/1)$ = 5.2 bits
- outcome of a Red Sox game: 1 bit

### Encoding

- Encoding describes the process of
    assigning representations to information
- Choosing an appropriate and efficient encoding is a 
  real engineering challenge
- Impacts design at many levels
  - Mechanism (devices, # of components used)
  - Efficiency (bits used)
  - Reliability (noise)
  - Security (encryption)

### Fixed-length encodings

If all choices are equally likely (or we have no reason to expect otherwise), then a fixed-length code is often used. Such a code will use at least enough bits to represent the information content.

### Encoding numbers
It is straightforward to encode positive integers as a sequence of bits.Each bit is assigned a weight. Ordered from right to left, these weights areincreasing powers of 2. The value of an n-bit number encoded in this fashion is given by the following formula
$ v = \sum ^ {n-1} _ {i=0} 2 ^ {i} b_{i}$

### Hamming Distance
### Error Detection
### Error Correction

## Summary

• Information resolves uncertainty
• Choices equally probable:
• N choices down to M log2 (N/M) bits of information
• use fixed-length encodings
• encoding numbers: 2’s complement signed integers
• Choices not equally probable:
• choicei with probability pi log2(1/pi ) bits of information
• average number of bits = pi log2 (1/pi )
• use variable-length encodings
• To detect D-bit errors: Hamming distance > D
• To correct D-bit errors: Hamming distance > 2D Next time
• encoding information electrically
• the digital abstraction
• combinational devices